{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cloud-Driven Loan Default Predictor using Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'boto3'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m confusion_matrix, classification_report\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mboto3\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msagemaker\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_execution_role\n\u001b[0;32m     11\u001b[0m warnings\u001b[38;5;241m.\u001b[39mfilterwarnings(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'boto3'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import resample, shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import warnings\n",
    "import boto3\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task I - Data Loading\n",
    "\n",
    "Instructions:\n",
    "- Build the S3 path for the dataset loan_cleaned_data.csv using string formatting to concatenate the bucket name, folder name and file key i.e the name of the dataset.\n",
    "- Note: Bucket name - than dataXYZXYZ (XYZXYZ can be any random integers) & Folder name - than cleaned data.\n",
    "- Load the dataset into a pandas DataFrame.\n",
    "\n",
    "Hint: Sample S3 URI - \"s3://bucket_name/folder_name/file_name.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = 'data123456'  # Replace with your actual bucket name\n",
    "folder_name = 'cleaned data'\n",
    "data_key = 'loan_cleaned_data.csv'\n",
    "data_location = f's3://{bucket}/{folder_name}/{data_key}'\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv(data_location)\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task II - Feature Engineering\n",
    "\n",
    "Instructions:\n",
    "- Convert the values in the categorical column 'purpose' into numerical format using One-hot Encoding.\n",
    "- The datatype of the new columns should be int."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform one-hot encoding on the 'purpose' column\n",
    "data = pd.get_dummies(data, columns=['purpose'], dtype=int)\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task III - Data Preprocessing\n",
    "\n",
    "Instructions:\n",
    "- Inspect the target column 'not_fully_paid' and identify the count of records belonging to the two classes.\n",
    "- Filter out the majority and minority classes and store them separately.\n",
    "- Handle the data imbalance by oversampling the minority class using the resample method so that the final count of records in both the classes becomes equal.\n",
    "- Store the result in the variable df_minority_upsampled.\n",
    "- Concatenate the upsampled minority data with the majority and assign the result to the new dataframe df.\n",
    "- Inspect the target column of the new dataframe to verify that the data is balanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate majority and minority classes\n",
    "df_majority = data[data['not_fully_paid'] == 0]\n",
    "df_minority = data[data['not_fully_paid'] == 1]\n",
    "\n",
    "# Upsample minority class\n",
    "df_minority_upsampled = resample(df_minority, \n",
    "                                 replace=True,\n",
    "                                 n_samples=len(df_majority),\n",
    "                                 random_state=42)\n",
    "\n",
    "# Combine majority class with upsampled minority class\n",
    "df = pd.concat([df_majority, df_minority_upsampled])\n",
    "\n",
    "# Display the distribution of target variable\n",
    "print(df['not_fully_paid'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task IV - Model Training\n",
    "\n",
    "Instructions:\n",
    "- Drop the columns 'slno' and 'not_fully_paid' and create a dataframe of independent variables named X.\n",
    "- Filter the dependent variable and store it in y.\n",
    "- Split the data into training and test sets using 60:40 ratio. Use a random state equal to 42.\n",
    "- Train a Random Forest Classifier model called rf using the training data. Use a random state equal to 42."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create X and y data for train-test split\n",
    "X = df.drop(['slno', 'not_fully_paid'], axis=1)\n",
    "y = df['not_fully_paid']\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "\n",
    "# Train a Random Forest Classifier model\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "print(\"Model training completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task V - Model Evaluation\n",
    "\n",
    "Instructions:\n",
    "- Predict using the trained Random Forest Classifier model rf on the test data X_test.\n",
    "- Evaluate the predictions by comparing it with the actual test data y_test.\n",
    "- Print the classification report to determine the evaluation metric scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict using the trained Random Forest Classifier model\n",
    "pred = rf.predict(X_test)\n",
    "\n",
    "# Print the classification report\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task VI - Saving the Model to AWS S3\n",
    "\n",
    "Instructions:\n",
    "- Serialize the trained Random Forest model using joblib.\n",
    "- Initialize the S3 client using the boto3 library.\n",
    "- Save the serialized model to a temporary file using tempfile.\n",
    "- Upload the model file to the specified S3 bucket named loan-data.\n",
    "- Ensure the model is saved as model.pkl in the S3 bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "import joblib\n",
    "\n",
    "BUCKET_NAME = 'loan-data'\n",
    "s3_client = boto3.client('s3')\n",
    "model_name = 'model.pkl'\n",
    "\n",
    "# Save to S3\n",
    "with tempfile.TemporaryFile() as fp:\n",
    "    joblib.dump(rf, fp)\n",
    "    fp.seek(0)\n",
    "    s3_client.put_object(\n",
    "        Body=fp.read(),\n",
    "        Bucket=BUCKET_NAME,\n",
    "        Key=model_name\n",
    "    )\n",
    "\n",
    "print(f'Model saved to S3 as: {model_name}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
